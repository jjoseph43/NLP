{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8deab543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk;\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import ptb\n",
    "from nltk.tag import UnigramTagger "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0049a4d2",
   "metadata": {},
   "source": [
    "### 1.\tRun one of the part-of-speech (POS) taggers available in Python. \n",
    "\n",
    "a.\tFind the longest sentence you can, longer than 10 words, that the POS tagger tags correctly. Show the input and output.\n",
    "\n",
    "b.\tFind the shortest sentence you can, shorter than 10 words, that the POS tagger fails to tag 100 percent correctly. Show the input and output. Explain your conjecture as to why the tagger might have been less than perfect with this sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "049968ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pre-analyzed sentence       ['There', 'were', 'many', 'books', 'on', 'the', 'bookshelf', 'at', 'the', 'closest', 'library', '.']\n",
      " Post-analyzed sentence       [('There', 'EX'), ('were', 'VBD'), ('many', 'JJ'), ('books', 'NNS'), ('on', 'IN'), ('the', 'DT'), ('bookshelf', 'NN'), ('at', 'IN'), ('the', 'DT'), ('closest', 'JJS'), ('library', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Tagging a longer sentence (greater than 10 words)\n",
    "examplesentence = word_tokenize(\"There were many books on the bookshelf at the closest library.\")\n",
    "print(\" Pre-analyzed sentence      \",examplesentence)\n",
    "Analyzedtext = nltk.pos_tag(examplesentence)\n",
    "print(\" Post-analyzed sentence      \",Analyzedtext)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e96b1f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pre-analyzed sentence       ['He', 'worked', 'for', 'synergy', 'systems', 'window', 'company', 'for', 'awhile', '.']\n",
      " Post-analyzed sentence       [('He', 'PRP'), ('worked', 'VBD'), ('for', 'IN'), ('synergy', 'JJ'), ('systems', 'NNS'), ('window', 'VBP'), ('company', 'NN'), ('for', 'IN'), ('awhile', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Tagging a shorter sentence that produces incorrect tagging\n",
    "examplesentence = word_tokenize(\"He worked for synergy systems window company for awhile.\")\n",
    "print(\" Pre-analyzed sentence      \",examplesentence)\n",
    "Analyzedtext = nltk.pos_tag(examplesentence)\n",
    "print(\" Post-analyzed sentence      \",Analyzedtext)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb11c3d",
   "metadata": {},
   "source": [
    " \n",
    " The POS tagger saw that synergy was a adjecticve even though it was part of the name so should be noun. Awhile should also not be a noun, it should be an adjective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218ae8e0",
   "metadata": {},
   "source": [
    "### 2.\tRun a different POS tagger in Python. Process the same two sentences from question 1.\n",
    "\n",
    "a.\tDoes it produce the same or different output?\n",
    "\n",
    "\n",
    "b.\tExplain any differences as best you can.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f53fb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There PRON\n",
      "were AUX\n",
      "many ADJ\n",
      "books NOUN\n",
      "on ADP\n",
      "the DET\n",
      "bookshelf NOUN\n",
      "at ADP\n",
      "the DET\n",
      "closest ADJ\n",
      "library NOUN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "#This is with using Spacy library to do the POS tagging\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"There were many books on the bookshelf at the closest library.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa534810",
   "metadata": {},
   "source": [
    "This was pretty similar to the nltk tagging that was done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6c9b6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He PRON\n",
      "worked VERB\n",
      "for ADP\n",
      "synergy NOUN\n",
      "systems NOUN\n",
      "window NOUN\n",
      "company NOUN\n",
      "for ADP\n",
      "awhile ADV\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "#This is with using Spacy library to do the POS tagging for the second sentence\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"He worked for synergy systems window company for awhile.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd28ecc",
   "metadata": {},
   "source": [
    "Synergy  counts as a noun now  the  word awhile seems to be more correctly tagged now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa2d175",
   "metadata": {},
   "source": [
    "3.\tIn a news article from this weekâ€™s news, find a random sentence of at least 10 words.\n",
    "\n",
    "    a.\tLooking at the Penn tag set, manually POS tag the sentence yourself.\n",
    "\n",
    "    b.\tNow run the same sentences through both taggers that you implemented for questions 1 and 2. Did either of the taggers produce the same results as you had created manually?\n",
    "    \n",
    "    c.\tExplain any differences between the two taggers and your manual tagging as much as you can.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c467720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Djokovic became embroiled in controversy earlier this year after attempting to enter Australia without a valid vaccination exemption.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "Originalnews = \"Djokovic became embroiled in controversy earlier this year after attempting to enter Australia without a valid vaccination exemption.\"\n",
    "print (Originalnews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b9a054",
   "metadata": {},
   "source": [
    "Djokovic - NNP \n",
    "\n",
    "became-VBD \n",
    "\n",
    "embroiled-\tJJ \n",
    "\n",
    "in- IN\n",
    "\n",
    "controversy-NN\n",
    "\n",
    "earlier-\tJJ\n",
    "\n",
    "this -\tPRP\n",
    "\n",
    "year -NN\n",
    "\n",
    "after - IN\n",
    "\n",
    "attempting -VB\n",
    "\n",
    "to -IN\n",
    "\n",
    "enter -VB\n",
    "\n",
    "Australia - NNP \n",
    "\n",
    "without - IN\n",
    "\n",
    "a - IN\n",
    "\n",
    "valid- JJ\n",
    "\n",
    "vaccination  -\tJJ\n",
    "\n",
    "exemption. -NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71e4ecb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pre-analyzed sentence       ['Djokovic', 'became', 'embroiled', 'in', 'controversy', 'earlier', 'this', 'year', 'after', 'attempting', 'to', 'enter', 'Australia', 'without', 'a', 'valid', 'vaccination', 'exemption', '.']\n",
      "\n",
      "NLTK\n",
      " Post-analyzed sentence       [('Djokovic', 'NNP'), ('became', 'VBD'), ('embroiled', 'VBN'), ('in', 'IN'), ('controversy', 'NN'), ('earlier', 'RBR'), ('this', 'DT'), ('year', 'NN'), ('after', 'IN'), ('attempting', 'VBG'), ('to', 'TO'), ('enter', 'VB'), ('Australia', 'NNP'), ('without', 'IN'), ('a', 'DT'), ('valid', 'JJ'), ('vaccination', 'NN'), ('exemption', 'NN'), ('.', '.')]\n",
      "\n",
      "SPACY\n",
      "Djokovic PROPN\n",
      "became AUX\n",
      "embroiled VERB\n",
      "in ADP\n",
      "controversy NOUN\n",
      "earlier ADV\n",
      "this DET\n",
      "year NOUN\n",
      "after ADP\n",
      "attempting VERB\n",
      "to PART\n",
      "enter VERB\n",
      "Australia PROPN\n",
      "without ADP\n",
      "a DET\n",
      "valid ADJ\n",
      "vaccination NOUN\n",
      "exemption NOUN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "# Tagging with NLTK\n",
    "examplesentence = word_tokenize(\"Djokovic became embroiled in controversy earlier this year after attempting to enter Australia without a valid vaccination exemption.\")\n",
    "print(\" Pre-analyzed sentence      \",examplesentence)\n",
    "print()\n",
    "print(\"NLTK\")\n",
    "Analyzedtext = nltk.pos_tag(examplesentence)\n",
    "print(\" Post-analyzed sentence      \",Analyzedtext)\n",
    "print()\n",
    "print(\"SPACY\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Djokovic became embroiled in controversy earlier this year after attempting to enter Australia without a valid vaccination exemption.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397251a9",
   "metadata": {},
   "source": [
    " In this sentence there does not seem to be as much differences between the two taggers and the manual tagging that I completed manually.It could be as it is a more straightforward sentence. The vaccination I thought should be an adjective as it is describing a type of exemption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c62a88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
