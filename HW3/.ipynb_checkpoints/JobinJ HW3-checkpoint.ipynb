{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4b555ac",
   "metadata": {},
   "source": [
    "### 1.\tCompare your given name with your nickname (if you donâ€™t have a nickname, invent one for this assignment) by answering the following questions:\n",
    "a.\tWhat is the edit distance between your nickname and your given name?\n",
    "b.\tWhat is the percentage string match \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a60b831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "381a79eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The edit distance between name and the nickname  is  3\n"
     ]
    }
   ],
   "source": [
    "#  putting both names in to two different strings \n",
    "orginalname = \"Jobin\"\n",
    "nickname = \"Jobeans\"\n",
    "\n",
    "\n",
    "#using the edit distance function as part of the NLTK package\n",
    "nltk.edit_distance(orginalname, nickname)\n",
    "print(\"The edit distance between name and the nickname  is \", nltk.edit_distance(orginalname, nickname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bba89bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percent that the  name and the nickname matches is  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# looking at the percentage of  string match \n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "percentmatch = similar(orginalname, nickname)\n",
    "print(\"The percent that the  name and the nickname matches is \", percentmatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965dcef8",
   "metadata": {},
   "source": [
    "## 2.\n",
    "Find a friend (or family member or classmate) who you know has read a certain book. Without your friend knowing, copy the first two sentences of that book. Now rewrite the words from those sentences, excluding stop words. Now tell your friend to guess which book the words are from by reading them just that list of words. Did you friend correctly guess the book on the first try? What did he or she guess? Explain why you think you friend either was or was not able to guess the book from hearing the list of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "740210eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We', 'begin', 'with', 'the', 'stars', ',', 'then', 'asend', 'up', 'and', 'away', 'out', 'to', 'the', 'galaxy', ',', 'the', 'universe', ',', 'beyond', '.', 'What', 'did', 'Buzz', 'Lightyear', 'say', 'in', 'Toy', 'Story']\n",
      "['We', 'begin', 'stars', ',', 'asend', 'away', 'galaxy', ',', 'universe', ',', 'beyond', '.', 'What', 'Buzz', 'Lightyear', 'say', 'Toy', 'Story']\n"
     ]
    }
   ],
   "source": [
    "# found this  method to remove the stop words \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "example_sent = \"We begin with the stars, then asend up and away out to the galaxy, the universe, beyond. What did Buzz Lightyear say in Toy Story \"\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "word_tokens = word_tokenize(example_sent)\n",
    "\n",
    "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "\n",
    "filtered_sentence = []\n",
    "\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "\n",
    "print(word_tokens)\n",
    "print(filtered_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18c18b1",
   "metadata": {},
   "source": [
    " The friend that  asked about the  text document was very close. He  thought it was astrophysics for people in a hurry ,  but the actual book was  welcome to the universe . This was really close  because it was done by the same author. It could be hard in this case because it was a simmilar subject that both books had incorporated. On the second guess he was able to get the right book title."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e53820",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3a38f9",
   "metadata": {},
   "source": [
    "Run one of the stemmers available in Python. Run the same two sentences from question 2 above through the stemmer and show the results. How many of the outputted stems are valid morphological roots of the corresponding words? Express this answer as a percentage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce8808da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We  :  we\n",
      "begin  :  begin\n",
      "with  :  with\n",
      "the  :  the\n",
      "stars  :  star\n",
      ",  :  ,\n",
      "then  :  then\n",
      "asend  :  asend\n",
      "up  :  up\n",
      "and  :  and\n",
      "away  :  away\n",
      "out  :  out\n",
      "to  :  to\n",
      "the  :  the\n",
      "galaxy  :  galaxi\n",
      ",  :  ,\n",
      "the  :  the\n",
      "universe  :  univers\n",
      ",  :  ,\n",
      "beyond  :  beyond\n",
      ".  :  .\n",
      "What  :  what\n",
      "did  :  did\n",
      "Buzz  :  buzz\n",
      "Lightyear  :  lightyear\n",
      "say  :  say\n",
      "in  :  in\n",
      "Toy  :  toy\n",
      "Story  :  stori\n"
     ]
    }
   ],
   "source": [
    "# import these modules\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# choose some words to be stemmed\n",
    "words = ['We', 'begin', 'with', 'the', 'stars', ',', 'then', 'asend', 'up', 'and', 'away', 'out', 'to', 'the', 'galaxy', ',', 'the', 'universe', ',', 'beyond', '.', 'What', 'did', 'Buzz', 'Lightyear', 'say', 'in', 'Toy', 'Story']\n",
    "\n",
    "for w in words:\n",
    "\tprint(w, \" : \", ps.stem(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b06d621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The  percent correct the stemmer was able to find  0.88\n"
     ]
    }
   ],
   "source": [
    " # The porter stemmer that is part of the NLTK pakage was able to get some of the words correctly matched with their root words \n",
    "print(\"The  percent correct the stemmer was able to find \",(22/25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347d96ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
