{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5376f25",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-3-28d0950641ef>, line 102)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-28d0950641ef>\"\u001b[1;36m, line \u001b[1;32m102\u001b[0m\n\u001b[1;33m    \"Review: Love is complicated in Ugly and Wonderful Things ..']},\u001b[0m\n\u001b[1;37m                                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#import pattern.en\n",
    "import re\n",
    "import string\n",
    "from nltk.cluster.util import cosine_distance\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "#%%\n",
    "# Supporting functions, taken from Sarkar\n",
    "#\n",
    "def remove_characters_after_tokenization(tokens):\n",
    "    pattern = re.compile('[{}]'.format(re.escape(string.punctuation)))\n",
    "    filtered_tokens = filter(None, [pattern.sub('', token) for token in tokens])\n",
    "    return filtered_tokens\n",
    "\n",
    "def bow_extractor(corpus, ngramRange=(1,1)):\n",
    "    vectorizer = CountVectorizer(min_df=1, ngram_range=ngramRange)\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features\n",
    "\n",
    "def build_feature_matrix(documents, feature_type='frequency'):\n",
    "    feature_type = feature_type.lower().strip()  \n",
    "    \n",
    "    if feature_type == 'binary':\n",
    "        vectorizer = CountVectorizer(binary=True, min_df=1, \n",
    "                                     ngram_range=(1, 1))\n",
    "    elif feature_type == 'frequency':\n",
    "        vectorizer = CountVectorizer(binary=False, min_df=1, \n",
    "                                     ngram_range=(1, 1))\n",
    "    elif feature_type == 'tfidf':\n",
    "        vectorizer = TfidfVectorizer(min_df=1, \n",
    "                                     ngram_range=(1, 1))\n",
    "    else:\n",
    "        raise Exception(\"Wrong feature type entered. Possible values: 'binary', 'frequency', 'tfidf'\")\n",
    "\n",
    "    feature_matrix = vectorizer.fit_transform(documents).astype(float)    \n",
    "    return vectorizer, feature_matrix\n",
    "\n",
    "def compute_cosine_similarity(doc_features, corpus_features,\n",
    "                              top_n=1):\n",
    "    # get document vectors\n",
    "    doc_features = doc_features.toarray()[0]\n",
    "    corpus_features = corpus_features.toarray()\n",
    "    # compute similarities\n",
    "    similarity = np.dot(doc_features, \n",
    "                        corpus_features.T)\n",
    "    # get docs with highest similarity scores\n",
    "    top_docs = similarity.argsort()[::-1][:top_n]\n",
    "    top_docs_with_score = [(index, round(similarity[index], 2))\n",
    "                            for index in top_docs]\n",
    "    return top_docs_with_score\n",
    "#%%\n",
    "import nltk\n",
    "nltk.download('wordnet') # first-time use only\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "def LemTokens(tokens):\n",
    "     return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "     return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
    "#%%\n",
    "\n",
    "AmazonBookList =  ['All the Ugly and Wonderful Things: A Novel',\n",
    "                   'The Tuscan Child',\n",
    "                   'Where the Crawdads Sing',\n",
    "                   'The Nightingale: A Novel',\n",
    "                   'The Goldfinch: A Novel (Pulitzer Prize for Fiction)',\n",
    "                   'The Life We Bury',\n",
    "                   'All the Light We Cannot See: A Novel',\n",
    "                   'Spilled Milk: Based on a true story',\n",
    "                   'What Alice Forgot',\n",
    "                   'The Flight Attendant: A Novel',\n",
    "                   'Winter Garden',\n",
    "                   \"The Storyteller's Secret: A Novel\",\n",
    "                   'Ordinary Grace: A Novel',\n",
    "                   'All the Ugly and Wonderful Things: A Novel',\n",
    "                   'It Ends with Us: A Novel',\n",
    "                   'The Shack: Where Tragedy Confronts Eternity',\n",
    "                   'Beneath a Scarlet Sky: A Novel',\n",
    "                   'Before We Were Yours: A Novel',\n",
    "                   'Small Great Things: A Novel',\n",
    "                   \"The Boy on the Wooden Box: How the Impossible Became Possible . . . on Schindler's List\",\n",
    "                   'A Man Called Ove: A Novel',\n",
    "                   \"The Ladies' Room\",\n",
    "                   'The Butterfly Garden (The Collector Book 1)',\n",
    "                   'HOSTILE WITNESS: A Josie Bates Thriller (The Witness Series Book 1)']\n",
    "\n",
    "\n",
    "#\n",
    "stopword_list = ['a','the','and','novel','s']\n",
    "\n",
    "GoogleResults = [{'All the Ugly and Wonderful Things: A Novel':[\"All the Ugly\\\n",
    "                and Wonderful Things: A Novel Kindle Edition by Bryn Greenwood \\\n",
    "                A powerful novel you won't soon forget, Bryn Greenwood's All\\\n",
    "                the Ugly and Wonderful Things challenges all we know and\\\n",
    "                believe about love. A beautiful and provocative love story\\\n",
    "                between two unlikely people and the hard-won relationship that\\\n",
    "                elevates them above the Midwestern meth lab backdrop of their\\\n",
    "                lives.\",\n",
    "                \"Review: Love is complicated in Ugly and Wonderful Things ..']},\n",
    "     {}]\n",
    "#%%\n",
    "\n",
    "\n",
    "#\n",
    "# Create tokenized list of each title\n",
    "#\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for title in AmazonBookList:\n",
    "    tokens = []\n",
    "    title = title.lower()\n",
    "    tokens = word_tokenize(title)\n",
    "    tokens = remove_characters_after_tokenization(tokens)\n",
    "    filteredTokens = [token for token in tokens if token not in stopword_list]      \n",
    "#    tfidf_vectorizer, tfidf_features = build_feature_matrix(filteredTokens,\n",
    "#                                                        feature_type='tfidf')\n",
    "    AmazonTokens.append(filteredTokens)  \n",
    "#%%\n",
    "   \n",
    "#%%\n",
    "TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=stopword_list)\n",
    "def cos_similarity(textlist):\n",
    "    tfidf = TfidfVec.fit_transform(textlist)\n",
    "    return (tfidf * tfidf.T).toarray()\n",
    "titleMatrix = cos_similarity(AmazonBookList) \n",
    "titleArray = np.asarray(titleMatrix).reshape(-1)\n",
    "titleArray.sort().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48a48ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
